{
  "226": {
    "inputs": {
      "seed": 422866330789929,
      "steps": 35,
      "cfg": 7,
      "sampler_name": "euler_ancestral",
      "scheduler": "normal",
      "denoise": 1,
      "model": [
        "239",
        0
      ],
      "positive": [
        "230",
        0
      ],
      "negative": [
        "270",
        0
      ],
      "latent_image": [
        "232",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "227": {
    "inputs": {
      "ckpt_name": "juggernautXL_juggXIByRundiffusion.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "230": {
    "inputs": {
      "strength": 0.8300000000000001,
      "conditioning": [
        "268",
        0
      ],
      "control_net": [
        "231",
        0
      ],
      "image": [
        "244",
        0
      ]
    },
    "class_type": "ControlNetApply",
    "_meta": {
      "title": "Apply ControlNet"
    }
  },
  "231": {
    "inputs": {
      "control_net_name": "t2i-adapter-depth-midas-sdxl-1.0.safetensors"
    },
    "class_type": "ControlNetLoader",
    "_meta": {
      "title": "Load ControlNet Model"
    }
  },
  "232": {
    "inputs": {
      "width": 1024,
      "height": 1024,
      "batch_size": 1
    },
    "class_type": "EmptyLatentImage",
    "_meta": {
      "title": "Empty Latent Image"
    }
  },
  "233": {
    "inputs": {
      "samples": [
        "226",
        0
      ],
      "vae": [
        "227",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "239": {
    "inputs": {
      "model": [
        "227",
        0
      ],
      "clip": [
        "227",
        1
      ],
      "lora_stack": [
        "240",
        0
      ]
    },
    "class_type": "CR Apply LoRA Stack",
    "_meta": {
      "title": "üíä CR Apply LoRA Stack"
    }
  },
  "240": {
    "inputs": {
      "switch_1": "Off",
      "lora_name_1": "last.safetensors",
      "model_weight_1": 1,
      "clip_weight_1": 1,
      "switch_2": "Off",
      "lora_name_2": "None",
      "model_weight_2": 1,
      "clip_weight_2": 1,
      "switch_3": "Off",
      "lora_name_3": "None",
      "model_weight_3": 0.7000000000000001,
      "clip_weight_3": 1
    },
    "class_type": "CR LoRA Stack",
    "_meta": {
      "title": "üíä CR LoRA Stack"
    }
  },
  "244": {
    "inputs": {
      "upscale_method": "nearest-exact",
      "width": 1024,
      "height": 1024,
      "crop": "center",
      "image": [
        "265",
        0
      ]
    },
    "class_type": "ImageScale",
    "_meta": {
      "title": "Upscale Image"
    }
  },
  "265": {
    "inputs": {
      "image": ""
    },
    "class_type": "ETN_LoadImageBase64",
    "_meta": {
      "title": "Load Image (Base64)"
    }
  },
  "266": {
    "inputs": {
      "filename_prefix": "ComfyUI",
      "images": [
        "233",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  },
  "267": {
    "inputs": {
      "text_positive": [
        "269",
        0
      ],
      "text_negative": "bad art, ugly, deformed, watermark, duplicated, nsfw",
      "style": "enhance",
      "log_prompt": "No",
      "style_name": ""
    },
    "class_type": "SDXLPromptStyler",
    "_meta": {
      "title": "SDXL Prompt Styler"
    }
  },
  "268": {
    "inputs": {
      "width": 1024,
      "height": 1024,
      "crop_w": 0,
      "crop_h": 0,
      "target_width": 1024,
      "target_height": 1024,
      "text_g": [
        "267",
        0
      ],
      "text_l": [
        "267",
        0
      ],
      "clip": [
        "239",
        1
      ]
    },
    "class_type": "CLIPTextEncodeSDXL",
    "_meta": {
      "title": "CLIPTextEncodeSDXL"
    }
  },
  "269": {
    "inputs": {
      "prompt": ""
    },
    "class_type": "CR Prompt Text",
    "_meta": {
      "title": "‚öôÔ∏è CR Prompt Text"
    }
  },
  "270": {
    "inputs": {
      "width": 1024,
      "height": 1024,
      "crop_w": 0,
      "crop_h": 0,
      "target_width": 1024,
      "target_height": 1024,
      "text_g": [
        "267",
        1
      ],
      "text_l": [
        "267",
        1
      ],
      "clip": [
        "239",
        1
      ]
    },
    "class_type": "CLIPTextEncodeSDXL",
    "_meta": {
      "title": "CLIPTextEncodeSDXL"
    }
  }
}